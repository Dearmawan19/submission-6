# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TFl7pLCev5tvCdBVappPsWv9Y_pVOutq

# Proyek Machine Learning - Dearmawan
# Diabetes Prediction Project

# Import Libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, mean_squared_error # Added MSE
import zipfile
import os

"""# Data Loading

"""

try:
    df = pd.read_csv('diabetes.csv')
    print("Dataset loaded successfully.")
except FileNotFoundError:
    print("Error: 'diabetes.csv' not found. Please ensure the dataset is in the correct directory.")

"""# Data Understanding"""

print("\n=== Data Understanding ===")

# Tampilkan 5 baris pertama
print("\nFirst 5 rows of the dataset:")
print(df.head())

"""- Dari lima baris pertama dataset ini, terlihat bahwa terdapat berbagai variasi dalam faktor-faktor yang berkaitan dengan diabetes seperti kadar glukosa, tekanan darah, ketebalan kulit, insulin, dan indeks massa tubuh (BMI). Misalnya, nilai glukosa berkisar antara 85 hingga 183 dan BMI berkisar antara 23.3 hingga 43.1. Terlihat pula bahwa sebagian pasien memiliki hasil “Outcome” 1, yang menunjukkan mereka terdiagnosis diabetes, dan sebagian lainnya tidak. Hal ini menunjukkan adanya potensi hubungan antara nilai-nilai medis ini dengan kemungkinan seseorang mengidap diabetes."""

# Informasi dasar dataset
print("\nDataset Info:")
df.info()

"""- Dataset ini terdiri dari 768 entri dan 9 kolom fitur tanpa nilai yang hilang (non-null), yang menunjukkan data bersih dan siap untuk analisis lebih lanjut. Mayoritas kolom bertipe numerik (int64 dan float64), mencakup faktor-faktor medis seperti glukosa, tekanan darah, insulin, hingga usia, yang dapat digunakan untuk memprediksi variabel target yaitu Outcome (indikasi diabetes). Struktur data yang lengkap ini sangat mendukung penerapan model pembelajaran mesin."""

# Deskripsi statistik
print("\nStatistical Description:")
print(df.describe())

"""- Berdasarkan deskripsi statistik, terlihat bahwa beberapa fitur seperti Glucose, BloodPressure, SkinThickness, Insulin, dan BMI memiliki nilai minimum 0, yang secara medis tidak realistis dan kemungkinan menunjukkan data hilang yang diisi dengan nol. Rata-rata usia pasien adalah sekitar 33 tahun, dengan nilai maksimum mencapai 81 tahun, dan rata-rata nilai glukosa adalah sekitar 121. Nilai Outcome memiliki mean 0.35, menunjukkan bahwa sekitar 35% dari pasien dalam dataset terdiagnosis diabetes. Temuan ini menunjukkan perlunya penanganan data nol sebelum analisis lanjutan atau pelatihan model."""

# Cek missing values (secara eksplisit NaN)
print("\nMissing Values Check (Explicit NaN):")
print(df.isnull().sum())

"""- Dari hasil pengecekan secara eksplisit, tidak ditemukan nilai kosong (NaN) pada keseluruhan dataset. Ini menunjukkan bahwa dataset secara teknis bersih dan tidak mengandung nilai hilang yang dikenali langsung oleh pandas."""

print("\nDuplicate Rows Check:")
duplicate_rows = df.duplicated().sum()
print(f"Number of duplicate rows: {duplicate_rows}")
if duplicate_rows > 0:
    print("Dropping duplicate rows...")
    df.drop_duplicates(inplace=True)
    print(f"Dataset shape after dropping duplicates: {df.shape}")
else:
    print("No duplicate rows found.")

"""- Tidak adanya duplikat"""

# Analisis nilai 0 yang mungkin merupakan missing values terselubung
print("\nChecking for zero values in relevant columns:")
zero_value_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
print((df[zero_value_cols] == 0).sum())
# Nilai 0 pada kolom ini tidak logis secara medis (kecuali mungkin Insulin pada kasus tertentu, tapi tetap mencurigakan)

"""- Meskipun tidak ada nilai NaN, ditemukan sejumlah nilai nol pada fitur penting seperti Glucose (5 data), BloodPressure (35), SkinThickness (227), Insulin (374), dan BMI (11). Nilai nol ini secara medis tidak realistis dan kemungkinan besar merupakan representasi terselubung dari data yang hilang, sehingga perlu penanganan lebih lanjut seperti imputasi agar tidak mengganggu proses pelatihan model."""

# Visualisasi Distribusi Fitur
print("\nPlotting feature distributions...")
df.hist(bins=50, figsize=(20,15))
plt.suptitle("Feature Distributions")
plt.tight_layout(rect=[0, 0.03, 1, 0.98])
plt.show()

"""- Visualisasi distribusi fitur menunjukkan bahwa beberapa variabel seperti Insulin dan SkinThickness memiliki banyak nilai nol dan distribusi yang sangat miring, mengindikasikan kemungkinan adanya missing value terselubung. Selain itu, fitur Outcome terlihat tidak seimbang, dengan lebih banyak pasien non-diabetes dibandingkan yang terdiagnosis diabetes."""

# Visualisasi Box Plot untuk melihat outliers
print("\nPlotting boxplots for outlier detection...")
plt.figure(figsize=(20, 10))
sns.boxplot(data=df, orient='h')
plt.title("Box Plot of Features")
plt.show()

"""- Box plot menunjukkan bahwa sebagian besar fitur dalam dataset memiliki outlier, terutama pada variabel Insulin, Glucose, dan DiabetesPedigreeFunction, yang memiliki nilai ekstrem jauh di atas rentang normalnya."""

# Visualisasi Distribusi Target ('Outcome')
print("\nOutcome Distribution:")
outcome_counts = df['Outcome'].value_counts()
print(outcome_counts)
sns.countplot(x='Outcome', data=df)
plt.title('Distribution of Outcome (0: No Diabetes, 1: Diabetes)')
plt.show() # Tampilkan plot di .ipynb

"""- Distribusi Outcome menunjukkan ketidakseimbangan kelas, di mana jumlah pasien tanpa diabetes (kelas 0) lebih banyak (500 orang) dibandingkan dengan pasien yang terdiagnosis diabetes (kelas 1) sebanyak 268 orang. Ketidakseimbangan ini penting untuk diperhatikan dalam proses pemodelan karena model prediktif dapat cenderung mengutamakan kelas mayoritas, sehingga berisiko mengabaikan deteksi kasus diabetes yang sebenarnya lebih penting secara medis."""

# Visualisasi Korelasi antar Fitur
print("\nPlotting correlation heatmap...")
plt.figure(figsize=(12, 10))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Features')
plt.show()

"""- Berdasarkan matriks korelasi, fitur yang paling berkorelasi positif terhadap kemungkinan seseorang menderita diabetes (Outcome) adalah Glucose (0.47), diikuti oleh BMI (0.29), Age (0.24), dan Pregnancies (0.22). Hal ini menunjukkan bahwa kadar glukosa darah yang tinggi, indeks massa tubuh yang lebih besar, usia yang lebih tua, serta jumlah kehamilan yang lebih banyak cenderung berkaitan dengan risiko diabetes yang lebih tinggi. Sementara itu, fitur-fitur seperti BloodPressure, SkinThickness, dan Insulin memiliki korelasi yang lebih lemah terhadap Outcome, menunjukkan pengaruh yang relatif lebih kecil dalam konteks ini.

# Data Preparation
"""

# Mengganti nilai 0 yang tidak logis dengan NaN
print("\nReplacing illogical zero values with NaN...")
cols_to_replace = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
df[cols_to_replace] = df[cols_to_replace].replace(0, np.nan)

# Cek kembali missing values setelah penggantian
print("\nMissing Values Check after replacing zeros:")
print(df.isnull().sum())

"""- Adanya nilai nol yang tidak logis pada beberapa fitur seperti Glucose (5 missing), BloodPressure (35 missing), SkinThickness (227 missing), Insulin (374 missing), dan BMI (11 missing) setelah menggantikan nilai nol dengan NaN."""

# Imputasi missing values dengan median
# Median lebih robust terhadap outlier dibandingkan mean
print("\nImputing NaN values with the median...")
for col in cols_to_replace:
    if df[col].isnull().any():
       df[col].fillna(df[col].median(),inplace=True)

# Cek kembali missing values setelah imputasi
print("\nMissing Values Check after imputation:")
print(df.isnull().sum()) # Seharusnya sudah 0 semua

"""- Missing Value sudah teratasi setalah melakukan imputasi"""

print("\nHandling Outliers using IQR capping...")

features_to_cap = df.drop('Outcome', axis=1).columns

for column in features_to_cap:
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Capping the outliers
    initial_outliers_lower = df[df[column] < lower_bound].shape[0]
    initial_outliers_upper = df[df[column] > upper_bound].shape[0]

    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])
    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])

    capped_outliers_lower = df[df[column] < lower_bound].shape[0] # Should be 0
    capped_outliers_upper = df[df[column] > upper_bound].shape[0] # Should be 0

    if initial_outliers_lower > 0 or initial_outliers_upper > 0:
        print(f"Outliers capped in '{column}': {initial_outliers_lower} lower, {initial_outliers_upper} upper.")
    else:
        print(f"No outliers (or already within 1.5*IQR) found in '{column}'.")


print("\nPlotting boxplots after outlier capping...")
plt.figure(figsize=(20, 10))
sns.boxplot(data=df.drop('Outcome', axis=1), orient='h') # Exclude 'Outcome' for boxplot of features
plt.title("Box Plot of Features (After IQR Capping)")
plt.show()

"""- Outliers udh teratasi

# Split Data
"""

# Memisahkan fitur (X) dan target (y)
X = df.drop('Outcome', axis=1)
y = df['Outcome']
print("\nFeatures (X) and Target (y) separated.")
print("Shape of X:", X.shape)
print("Shape of y:", y.shape)

"""- Proses pemisahan fitur (X) dan target (y) menunjukkan bahwa dataset awal berisi 768 sampel dengan 8 fitur (X memiliki bentuk (768, 8)) dan 1 variabel target (y memiliki bentuk (768,)). Ini konsisten dengan struktur dataset diabetes yang digunakan, di mana 8 fitur seperti Pregnancies, Glucose, dan BMI digunakan untuk memprediksi variabel biner Outcome."""

# Membagi data menjadi training dan testing set (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
print("\nData split into training and testing sets.")
print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)
print("y_train shape:", y_train.shape)
print("y_test shape:", y_test.shape)
print("Train set Outcome distribution:\n", y_train.value_counts(normalize=True))
print("Test set Outcome distribution:\n", y_test.value_counts(normalize=True))

"""- Proses pemisahan data ke dalam set pelatihan dan pengujian menunjukkan pembagian yang optimal dengan 614 sampel untuk pelatihan (X_train: (614, 8), y_train: (614,)) dan 154 sampel untuk pengujian (X_test: (154, 8), y_test: (154,)), sesuai dengan rasio 80:20. Distribusi kelas 'Outcome' (0 untuk non-diabetes, 1 untuk diabetes) tetap seimbang melalui stratifikasi, dengan proporsi pada set pelatihan (0: 0.651466, 1: 0.348534) dan set pengujian (0: 0.649351, 1: 0.350649) yang hampir identik dengan distribusi asli data. Konsistensi ini memastikan bahwa model akan dilatih dan dievaluasi pada representasi yang adil dari data, mengurangi risiko bias dan meningkatkan keandalan hasil prediksi, terutama untuk dataset dengan kelas yang tidak seimbang seperti ini."""

# Feature Scaling menggunakan StandardScaler
# Scaling penting untuk algoritma seperti KNN
print("\nApplying StandardScaler to features...")
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Ubah kembali ke DataFrame untuk kemudahan inspeksi
X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)

print("\nScaled training data (first 5 rows):")
print(X_train_scaled.head())

"""- Penerapan StandardScaler pada fitur menunjukkan bahwa data telah berhasil dinormalisasi, seperti terlihat pada lima baris pertama data pelatihan yang memiliki nilai rata-rata mendekati 0 dan deviasi standar mendekati 1 untuk setiap fitur, seperti Pregnancies (-0.835135 hingga -1.153338), Glucose (-1.056427 hingga 0.811525), dan BMI (-0.769447 hingga 1.782373).

# Modeling
"""

print("\n=== Modeling ===")

# Model 1: K-Nearest Neighbors (KNN)
print("\nTraining K-Nearest Neighbors (KNN)...")
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train_scaled, y_train)

# Model 2: Random Forest
print("\nTraining Random Forest Classifier...")
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train_scaled, y_train)

# Model 3: Logistic Regression
print("\nTraining Logistic Regression Classifier...")
lr = LogisticRegression(random_state=42, solver='liblinear') # liblinear is good for small datasets
lr.fit(X_train_scaled, y_train)

# Hyperparameter Tuning untuk model terpilih ( Random Forest)
print("\nPerforming Hyperparameter Tuning for Random Forest using GridSearchCV...")

# Tentukan parameter grid yang lebih kecil untuk contoh cepat
param_grid_rf = {
    'n_estimators': [50, 100, 150],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 3]
}

# Gunakan cross-validation 3-fold saja untuk contoh
rf_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=42),
                       param_grid=param_grid_rf,
                       cv=3,
                       n_jobs=-1,
                       verbose=1,
                       scoring='accuracy')

rf_grid.fit(X_train_scaled, y_train)

print("\nBest parameters found for Random Forest:")
print(rf_grid.best_params_)

# Model terbaik dari GridSearchCV
best_rf = rf_grid.best_estimator_
print("\nBest Random Forest model trained with optimal parameters.")

"""- Hasil tuning hyperparameter pada model Random Forest menggunakan GridSearchCV, di mana dilakukan pencarian terhadap 36 kombinasi parameter dengan 3-fold cross-validation, menghasilkan total 108 pelatihan model. Hasil terbaik diperoleh dengan parameter n_estimators=150, min_samples_leaf=3, min_samples_split=2, dan tanpa batasan kedalaman pohon (max_depth=None).

# Evaluation
"""

# Helper function to print evaluation metrics
def evaluate_model(y_true, y_pred, model_name):
    print(f"\n--- {model_name} Evaluation ---")
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, zero_division=0) # Handles cases with no predicted positives
    recall = recall_score(y_true, y_pred, zero_division=0)       # Handles cases with no actual positives
    f1 = f1_score(y_true, y_pred, zero_division=0)               # Handles cases with no positives
    mse = mean_squared_error(y_true, y_pred) # MSE for classification (0/1 labels)

    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"Mean Squared Error (MSE): {mse:.4f}") # Added MSE

    print(f"\nConfusion Matrix ({model_name}):")
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues' if 'KNN' in model_name else ('Greens' if 'Base RF' in model_name else ('Oranges' if 'Tuned RF' in model_name else 'Purples')))
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.title(f'Confusion Matrix - {model_name}')
    plt.show()
    print(f"\nClassification Report ({model_name}):")
    print(classification_report(y_true, y_pred, zero_division=0))
    return accuracy, precision, recall, f1, mse

# Evaluasi Model KNN (Baseline)
y_pred_knn = knn.predict(X_test_scaled)
acc_knn, pre_knn, rec_knn, f1_knn, mse_knn = evaluate_model(y_test, y_pred_knn, "KNN (Baseline K=5)")

"""- Model K-Nearest Neighbors (KNN) dengan K=5 menunjukkan kinerja yang cukup baik dengan akurasi 75,32%. Namun, terdapat ketidakseimbangan performa antara kelas 0 dan kelas 1. Kelas 0 memiliki precision, recall, dan F1-score yang lebih tinggi (masing-masing 0,80, 0,83, dan 0,81) dibandingkan kelas 1 (0,66, 0,61, dan 0,63), yang mengindikasikan bahwa model lebih akurat dalam mengklasifikasikan kelas mayoritas. Hal ini juga tercermin pada confusion matrix, di mana terdapat 21 false negative untuk kelas 1 dan 17 false positive untuk kelas 0. Meskipun MSE tergolong rendah (0,2468), model ini bisa ditingkatkan lebih lanjut, terutama untuk meningkatkan sensitivitas terhadap kelas minoritas"""

# Evaluasi Model Random Forest (Baseline)
y_pred_rf_base = rf.predict(X_test_scaled)
acc_rf_base, pre_rf_base, rec_rf_base, f1_rf_base, mse_rf_base = evaluate_model(y_test, y_pred_rf_base, "Random Forest (Baseline)")

"""- Model ini memberikan performa terbaik secara keseluruhan dengan akurasi 76.62%, precision 0.6957, dan F1-score 0.64. Meskipun recall untuk kelas 1 masih rendah (0.59), model ini memiliki keseimbangan yang cukup baik antara precision dan recall. Confusion matrix menunjukkan 32 prediksi benar untuk kelas 1 dan 22 false negative, yang menunjukkan model masih kesulitan mengenali sebagian data positif, namun secara umum ini adalah baseline yang solid."""

# Evaluasi Model Random Forest (Tuned)
y_pred_rf_tuned = best_rf.predict(X_test_scaled)
acc_rf_tuned, pre_rf_tuned, rec_rf_tuned, f1_rf_tuned, mse_rf_tuned = evaluate_model(y_test, y_pred_rf_tuned, "Random Forest (Tuned)")

"""- Setelah tuning, performa model sedikit menurun dengan akurasi 75.97%, F1-score 0.6263, dan recall kelas 1 menurun menjadi 0.5741. Perubahan ini menunjukkan bahwa tuning belum berhasil meningkatkan generalisasi model dan justru sedikit memperburuk kemampuan model dalam mengenali kelas 1. False negative juga meningkat menjadi 23, sehingga sensitivitas model terhadap kelas minoritas perlu ditingkatkan."""

# Evaluasi Model Logistic Regression
y_pred_lr = lr.predict(X_test_scaled)
acc_lr, pre_lr, rec_lr, f1_lr, mse_lr = evaluate_model(y_test, y_pred_lr, "Logistic Regression")

"""- Model ini mencapai akurasi keseluruhan sebesar 71,43% pada data uji. Dari confusion matrix, terlihat bahwa dari 100 kasus aktual non-diabetes (label 0), 82 diprediksi dengan benar, sementara 18 salah diklasifikasikan sebagai diabetes. Untuk 54 kasus aktual diabetes (label 1), 28 berhasil diidentifikasi dengan benar, namun 26 kasus terlewatkan (menjadi false negative). Hal ini menghasilkan recall sebesar 0,5185 untuk kelas diabetes (1), yang mengindikasikan model ini berhasil mengidentifikasi sekitar 52% individu yang sebenarnya menderita diabetes, sedangkan presisi untuk kelas diabetes adalah 0,6087, artinya ketika model memprediksi diabetes, sekitar 61% prediksinya benar. F1-score sebesar 0,56 untuk kelas diabetes menunjukkan keseimbangan yang moderat antara presisi dan recall dalam memprediksi diabetes, dan Mean Squared Error (MSE) sebesar 0,2857 mencerminkan rata-rata kuadrat perbedaan antara hasil aktual dan prediksi biner.

# Kesimpulan Evaluasi
"""

print("\n=== Evaluation Summary ===")

results_summary = pd.DataFrame({
    'Model': ['KNN (Baseline)', 'Random Forest (Baseline)', 'Random Forest (Tuned)', 'Logistic Regression'],
    'Accuracy': [acc_knn, acc_rf_base, acc_rf_tuned, acc_lr],
    'Precision': [pre_knn, pre_rf_base, pre_rf_tuned, pre_lr],
    'Recall': [rec_knn, rec_rf_base, rec_rf_tuned, rec_lr],
    'F1 Score': [f1_knn, f1_rf_base, f1_rf_tuned, f1_lr],
    'MSE': [mse_knn, mse_rf_base, mse_rf_tuned, mse_lr]
})

print("\nModel Performance Metrics:")
print(results_summary.round(4)) # Round to 4 decimal places for display

print("\nComparing models based on F1-Score (often a good balance for classification):")
best_f1_model = results_summary.loc[results_summary['F1 Score'].idxmax()]
print(f"Best performing model based on F1-Score:\n{best_f1_model['Model']} with F1-Score: {best_f1_model['F1 Score']:.4f}")

print("\nComparing models based on Recall (if False Negative is more crucial):")
best_recall_model = results_summary.loc[results_summary['Recall'].idxmax()]
print(f"Best performing model based on Recall:\n{best_recall_model['Model']} with Recall: {best_recall_model['Recall']:.4f}")

print("\nComparing models based on MSE (lower is better):")
best_mse_model = results_summary.loc[results_summary['MSE'].idxmin()] # Lower MSE is better
print(f"Model with the lowest MSE:\n{best_mse_model['Model']} with MSE: {best_mse_model['MSE']:.4f}")


print("\nProject Finished.")

"""- Ringkasan evaluasi menunjukkan bahwa model Random Forest (Baseline) secara umum memberikan performa terbaik dengan F1-Score tertinggi (0.6400) dan MSE terendah (0.2338), menandakan keseimbangan yang baik antara presisi dan recall serta kesalahan prediksi yang paling kecil. Meskipun demikian, jika prioritas utama adalah meminimalkan false negative (kasus diabetes yang tidak terdeteksi), maka model KNN (Baseline) unggul dengan Recall tertinggi (0.6111). Model Logistic Regression menunjukkan performa paling rendah di antara semua model yang diuji pada sebagian besar metrik."""